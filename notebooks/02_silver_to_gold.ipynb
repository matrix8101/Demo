{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e39174-ac25-4dca-88e3-48c28cfaad23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../utils/common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b32d0bd3-21f5-4a09-8988-8de39759f601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load config and authenticate\n",
    "config = get_pipeline_config()\n",
    "authenticate_adls(config['storage_account'], config['secret_scope'])\n",
    "\n",
    "storage_account = config['storage_account']\n",
    "container_output = config['container_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3b1503-59d2-44bd-9dd5-48e4e1ec6d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Define paths to your Silver Delta tables\n",
    "# (Assuming your previous notebook created 'train' and 'test' folders)\n",
    "train_path = get_path(container_output, storage_account, \"silver/train\")\n",
    "test_path = get_path(container_output, storage_account, \"silver/test\")\n",
    "\n",
    "# 2. Read Silver Data\n",
    "df_train = spark.read.format(\"delta\").load(train_path)\n",
    "df_test = spark.read.format(\"delta\").load(test_path)\n",
    "\n",
    "# 3. Union them (Combining for a holistic view)\n",
    "df_combined = df_train.unionByName(df_test)\n",
    "\n",
    "# 4. Gold Transformation: Marketing Analysis\n",
    "# Let's see who has the most money and their conversion rate (y)\n",
    "df_gold_analysis = df_combined.groupBy(\"job\", \"education\").agg(\n",
    "    F.count(\"job\").alias(\"total_customers\"),\n",
    "    F.avg(\"balance\").alias(\"avg_balance\"),\n",
    "    F.sum(F.when(F.col(\"y\") == \"yes\", 1).otherwise(0)).alias(\"total_conversions\")\n",
    ")\n",
    "\n",
    "# 5. Add a calculation for conversion rate\n",
    "df_gold_analysis = df_gold_analysis.withColumn(\n",
    "    \"conversion_rate\", \n",
    "    (F.col(\"total_conversions\") / F.col(\"total_customers\")) * 100\n",
    ")\n",
    "\n",
    "# 6. Save to Gold\n",
    "gold_path = get_path(container_output, storage_account, \"gold/marketing_analysis\")\n",
    "\n",
    "df_gold_analysis.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(gold_path)\n",
    "\n",
    "print(f\"âœ… Gold analysis table created at: {gold_path}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
